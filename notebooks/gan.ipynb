{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GAN: Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generative model is pitted against an adversary: a discriminative model that learns to determine whether a sample is from the generative model distribution or the data distribution.\n",
    "\n",
    "**Setup**<br>\n",
    "* $p_{data}$: true data distribution over data $\\mathbf{x}\\in\\mathcal{X}$.\n",
    "* $p_g$: generators distribution over data $\\mathbf{x}\\in\\mathcal{X}$.\n",
    "* $p_{\\mathbf{z}}(\\mathbf{z})$: prior on input noise variables $\\mathbf{z}\\in\\mathcal{Z}$\n",
    "* Let $G:\\mathcal{Z}\\rightarrow\\mathcal{X}$ be the generator $G(\\mathbf{z};\\theta_g)$\n",
    "* Let $D:\\mathcal{X}\\rightarrow[0,1]$ be the discriminator $D(\\mathbf{x};\\theta_d)$, where $D(\\mathbf{x})$ is the probability that $\\mathbf{x}$ came from the data distribution $p_{data}$ than the generator distribution $p_g$.\n",
    "\n",
    "**The Objective Function**<br>\n",
    "$D$ and $G$ play the following two-player minimax game with the value function $V(D,G)$\n",
    "\n",
    "$$\\underset{G}{\\text{min }}\\underset{D}{\\text{max }}V(D,G)=\\mathbb{E}_{\\mathbf{x}\\sim p_{data}(\\mathbf{x})}\\Big[\\log D(\\mathbf{x})\\Big]+ \\mathbb{E}_{\\mathbf{z}\\sim p_{\\mathbf{z}}(\\mathbf{z})}\\bigg[\\log \\Big(1-D\\big(G(\\mathbf{z})\\big)\\Big)\\bigg]$$\n",
    "\n",
    "where \n",
    "* We would like to maximise the first term as this is the probability (output by model $D$) of the data point $\\mathbf{x}\\sim p_{data}$ coming from the data distribution $p_{data}$.\n",
    "* We would like to minimise the second term as this is the probability (output by model $D$) that the data point $G(\\mathbf{z})$ comes from the generative model distribution $p_g$.\n",
    "\n",
    "In practice, the original loss function may not provide sufficient gradients for $G$ to learn. This is because early in learning, $G$ is poor and $D$ can easily reject samples with high confidence such that $\\log\\Big(1-D\\big(G(\\mathbf{z})\\big)\\Big)\\rightarrow0$ as $D\\big(G(\\mathbf{z})\\big)\\approx0$. Instead we can use the below loss function,\n",
    "\n",
    "$$\\underset{G}{\\text{max }}\\underset{D}{\\text{max }}V(D,G)=\\mathbb{E}_{\\mathbf{x}\\sim p_{data}(\\mathbf{x})}\\Big[\\log D(\\mathbf{x})\\Big]+ \\mathbb{E}_{\\mathbf{z}\\sim p_{\\mathbf{z}}(\\mathbf{z})}\\Big[\\log D\\big(G(\\mathbf{z})\\big)\\Big]$$\n",
    "\n",
    "which has the same fixed point of the dynamics of $G$ and $D$ but provides much stronger gradients early in learning.\n",
    "\n",
    "**Convegence Results**<br>\n",
    "In this setup, for $G$ fixed the optimal discriminator $D$ is \n",
    "\n",
    "$$D^{\\star}_{G}(\\mathbf{x})=\\frac{p_{data}(\\mathbf{x})}{p_{data}(\\mathbf{x})+p_g(\\mathbf{x})}$$\n",
    "\n",
    "The training objective for $D$ can be interpreted as maximising the log-likelihood of the conditional probabiltiy $p(Y=y\\mid \\mathbf{x})$, where $y=1$ if $\\mathbf{x}$ comes from $p_{data}$ and $y=0$ if $\\mathbf{x}$ comes from $p_g$. The objective can be reformulated as,\n",
    "\n",
    "$$\\begin{align}\n",
    "V(D^{\\star}_G,G)&=\\underset{D}{\\text{max }}V(D,G)\\\\\n",
    "&=\\mathbb{E}_{\\mathbf{x}\\sim p_{data}(\\mathbf{x})}\\Big[\\log D^{\\star}_G(\\mathbf{x})\\Big]+ \\mathbb{E}_{\\mathbf{z}\\sim p_{\\mathbf{z}}(\\mathbf{z})}\\bigg[\\log \\Big(1-D^{\\star}_G\\big(G(\\mathbf{z})\\big)\\Big)\\bigg]\\\\\n",
    "&=\\mathbb{E}_{\\mathbf{x}\\sim p_{data}(\\mathbf{x})}\\Big[\\log D^{\\star}_G(\\mathbf{x})\\Big]+ \\mathbb{E}_{\\mathbf{z}\\sim p_{\\mathbf{z}}(\\mathbf{z})}\\bigg[\\log \\Big(1-D^{\\star}_G(\\mathbf{x})\\Big)\\bigg]\\\\\n",
    "&=\\mathbb{E}_{\\mathbf{x}\\sim p_{data}(\\mathbf{x})}\\bigg[\\log\\frac{p_{data}(\\mathbf{x})}{p_{data}(\\mathbf{x})+p_g(\\mathbf{x})}\\bigg]+ \\mathbb{E}_{\\mathbf{z}\\sim p_{\\mathbf{z}}(\\mathbf{z})}\\bigg[\\log\\frac{p_g(\\mathbf{x})}{p_{data}(\\mathbf{x})+p_g(\\mathbf{x})}\\bigg]\n",
    "\\end{align}$$\n",
    "\n",
    "The generator minimises the original objective for a fixed discriminator $D$. Hence the global minimum of the virtual training criterion $V(D^{\\star}_G,G)$ is achieved if and only if $p_g=p_{data}$. This means that $D^{\\star}_G=\\frac{1}{2}$ such that\n",
    "\n",
    "$$\\begin{align}\n",
    "V(D^{\\star}_G,G)&=-\\log4+KL\\bigg(p_{data}||\\frac{p_{data}+p_g}{2}\\bigg)+ KL\\bigg(p_g||\\frac{p_{data}+p_g}{2}\\bigg)\\\\\n",
    "&=-\\log4 + 2D_{JSD}(p_{data}||p_g)\n",
    "\\end{align}$$\n",
    "\n",
    "where $D_{JSD}$ is the Jenson-Shannon Divergence (the symmetric form of the KL divergence). Since the Jensenâ€“Shannon divergence between two distributions is always non-negative and zero only when they are equal, we that the optimal objective is $V(D^{\\star}_{G^{\\star}},G^{\\star})=\\underset{G}{\\text{min }}V(D^{\\star}_G,G)=-\\log4$.\n",
    "\n",
    "**The Training Algorithm**<br>\n",
    "In practice, we must implement the game using an iterative, numerical approach. Optimizing $D$ to completion in the inner loop of training is computationally prohibitive, and on finite datasets would result in overfitting. Instead, we alternate between $k$ steps of optimizing $D$ and one step of optimizing $G$. This results in $D$ being maintained near its optimal solution, so long as G changes slowly enough.\n",
    "\n",
    "For epochs $1,...,N$ do:<br>\n",
    "For k steps do:\n",
    "1. Sample minibatch of size $m$ from data: $\\mathbf{x}^{(1)},...,\\mathbf{x}^{(m)}\\sim p_{data}(\\mathbf{x})$\n",
    "2. Sample minibatch of size $m$ from noise: $\\mathbf{z}^{(1)},...,\\mathbf{z}^{(m)}\\sim p_{\\mathbf{z}}(\\mathbf{z})$\n",
    "3. Take a gradient ascent step on the discriminator parameters $\\theta_d$\n",
    "\n",
    "$$\\nabla_{\\theta_d}V(D,G)=\\frac{1}{m}\\nabla_{\\theta_d}\\sum^{m}_{i=1}\\bigg[\\log D\\Big(\\mathbf{x}^{(i)}\\Big) +\\log \\Big(1-D\\Big(G\\Big(\\mathbf{z}^{(i)}\\Big)\\Big)\\Big)\\bigg]$$\n",
    "\n",
    "end for <br>\n",
    "4. Sample minibatch of size $m$ from noise: $\\mathbf{z}^{(1)},...,\\mathbf{z}^{(m)}\\sim p_{\\mathbf{z}}(\\mathbf{z})$\n",
    "5. Take a gradient descent step on the generator parameters $\\theta_g$\n",
    "\n",
    "$$\\nabla_{\\theta_g}V(D,G)=\\frac{1}{m}\\nabla_{\\theta_d}\\sum^{m}_{i=1}\\log \\Big(1-D\\Big(G\\Big(\\mathbf{z}^{(i)}\\Big)\\Big)\\Big)$$\n",
    "\n",
    "end for\n",
    "\n",
    "**Challenges**<br>\n",
    "Working with GANs in practice is challenging because:\n",
    "1. Unstable optimisation procedure: generator and discriminator loss continue to oscillate without converging to clear stopping point.\n",
    "2. Potential for mode collapse: generator can get stuck producing one of a few types of samples over and over again.\n",
    "3. Difficulty in evaluation: due to the lack of a robust stopping criteria, it is difficult to know when exactly the GAN has finished training.\n",
    "\n",
    "Tips and tricks for training a GAN: https://github.com/soumith/ganhacks\n",
    "\n",
    "**References**<br>\n",
    "Original GAN paper: https://arxiv.org/abs/1406.2661 <br>\n",
    "NeurIPS GAN tutorial: https://arxiv.org/abs/1701.00160 <br>\n",
    "CS236 notes: https://deepgenerativemodels.github.io/notes/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GAN: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch-GAN: https://github.com/eriklindernoren/PyTorch-GAN#gan<br>\n",
    "https://github.com/BY571/GANs/blob/master/Basic%20GAN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# from torchvision import transforms\n",
    "# from torchvision.datasets import MNIST\n",
    "# # 60000 tuples with 1x28x28 image and corresponding label\n",
    "# data = MNIST('../data', \n",
    "#              train=True, \n",
    "#              download=False,\n",
    "#              transform = transforms.Compose([transforms.ToTensor()]))\n",
    "# # Split data into images and labels\n",
    "# x_train = data.train_data\n",
    "# y_train = data.train_labels\n",
    "# # Scale images from [0,255] to [-1,+1]\n",
    "# x_train = ((x_train.float() / 255) - 0.5) * 2\n",
    "# # Save as .npz\n",
    "# np.savez_compressed('../data/mnist', \n",
    "#                     a=x_train,\n",
    "#                     b=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data locally\n",
    "data = np.load('../data/mnist.npz')\n",
    "x_train = torch.Tensor(data['a'])\n",
    "y_train = torch.Tensor(data['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2520x2520 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise data\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, axes = plt.subplots(1,4, figsize=(35,35))\n",
    "imx, imy = (28,28)\n",
    "labels   = [0,1,2,3]\n",
    "for i, ax in enumerate(axes):\n",
    "    visual = np.reshape(x_train[labels[i]], (imx,imy))\n",
    "    ax.set_title(\"Example Data Image, y=\"+str(int(y_train[labels[i]])))\n",
    "    ax.imshow(visual, vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        \"\"\"\n",
    "        Generator Model.\n",
    "        \n",
    "        Arguments:\n",
    "        ----------\n",
    "        input_shape : `int`\n",
    "            Dimensionality of the latent space. (Default=100)\n",
    "        output_shape : `int`\n",
    "            Flattened size of image. (Default=784)\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        def block(in_shape, out_shape, normalize=True):\n",
    "            layers = [nn.Linear(in_shape, out_shape)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_shape, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers        \n",
    "        \n",
    "        self.model = nn.Sequential(*block(input_shape, 128, normalize=False),\n",
    "                                   *block(128, 128),\n",
    "                                   nn.Linear(128, output_shape),\n",
    "                                   nn.Tanh())\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.model(z)\n",
    "        x = x.view(x.size(0), *x_shape)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        \"\"\"\n",
    "        Discriminator Model.\n",
    "        \n",
    "        Arguments:\n",
    "        ----------\n",
    "        input_shape : `int`\n",
    "            Flattened size of image. (Default=784)\n",
    "        \"\"\"        \n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(nn.Linear(input_shape, 128),\n",
    "                                   nn.LeakyReLU(0.2, inplace=True),\n",
    "                                   nn.Linear(128, 128),\n",
    "                                   nn.LeakyReLU(0.2, inplace=True),\n",
    "                                   nn.Linear(128, 1),\n",
    "                                   nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_flat = x.view(x.size(0), -1)\n",
    "        y = self.model(x_flat)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "z_dim   = 100\n",
    "epochs  = 1\n",
    "batch_size = 64\n",
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n",
      "Generator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): BatchNorm1d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Linear(in_features=128, out_features=784, bias=True)\n",
      "    (6): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create DatatLoader \n",
    "dataset = data_utils.TensorDataset(x_train, y_train)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator     = Generator(z_dim, np.prod(x_train[0].shape))\n",
    "discriminator = Discriminator(np.prod(x_train[0].shape))\n",
    "\n",
    "# Send to GPU if available \n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "adversarial_loss.to(device)\n",
    "\n",
    "# Optimisers\n",
    "optimiser_G = torch.optim.Adam(generator.parameters(), lr=1e-4)\n",
    "optimiser_D = torch.optim.SGD(discriminator.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"Device: \", device)\n",
    "print(generator)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "measures = defaultdict(list)\n",
    "measures['loss_d']\n",
    "measures['loss_g']\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for step in range(k):    \n",
    "        # Train Discriminator\n",
    "        for i, (X,y) in enumerate(dataloader):\n",
    "            \n",
    "            # Adversarial ground truths\n",
    "            valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "            fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)            \n",
    "            \n",
    "            optimizer_D.zero_grad()\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "            real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "\n",
    "            batches_done = epoch * len(dataloader) + i\n",
    "            if batches_done % opt.sample_interval == 0:\n",
    "                save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)            \n",
    "    \n",
    "    # Train Generator\n",
    "    for i, (X,y) in enumerate(dataloader):\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)           \n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], z_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
